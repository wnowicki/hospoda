---
title: Podsumowanie konferencji AIBA 2025
layout: post
subtitle: Podsumowanie konferencji AIBA 2025
description: W odcinku omawiam swoje wnioski z konferencji AIBA 2025, skupiając się na trendach w AI, wyzwaniach związanych z wdrażaniem rozwiązań AI w przedsiębiorstwach oraz zmianach w infrastrukturze. Podkreślam znaczenie jakości i bezpieczeństwa AI, a także nowe funkcje GitHub Copilot, które wspierają proces developmentu. Ostatecznie, podsumowuję konferencję i jej wpływ na przyszłość AI.
date: 2025-10-14 09:00
author: wojtek
spotify:
  id: 6csb4M26X6xS61Key28lwa
  url: https://open.spotify.com/episode/6csb4M26X6xS61Key28lwa?si=EtC4GvAsStiHk1IBRw9Vfg
apple:
  url
youtube:
  url:
categories:
  - solo
tags:
  - konferencje
  - AI
  - przyszłość AI
  - asystenci AI
host: wnowicki
people:
toc: false
---

## Transkrypcja

> Transkrypcja jest generowana automatycznie

Rzeczy dzieją się w AI na tyle szybko, że już mówimy tutaj o poprzedniej epoce podejścia, która była raptem w 2023 roku.

To jest jedenasty odcinek podcastu hospoda.tech. Dzisiaj wyjątkowo bez standardowej struktury, ponieważ solo, czyli nagrywam już wszystko naraz. Dzisiaj będę podsumowywał krótką konferencję AIBA 2025, która odbyła się w Katowicach w ubiegłym tygodniu, dokładnie w dniach 8, 9, 10 października.

My tam byliśmy 8.9., ponieważ ostatni dzień to były workshopy. I na pewno nie chcę wam tutaj przekazywać całkowicie treści konferencji, bo jeżeli ktoś byłby zainteresowany, to należało tam pojechać, wziąć udział lub ewentualnie zapoznać się z materiałami, które są udostępniane. Ja raczej powiem swoją subiektywną opinię, swoje wnioski, które wyciągnąłem z tej konferencji na temat tego...

Co się dzieje w świecie no oczywiście bo o tym teraz wszyscy mówią a zachęcam was do subskrybowania podcastu wiadomo w aplikacji w której mnie słuchacie w tej chwili lub nie wiem YouTube to przez stronę internetową ale tam też można subskrybować. Transkrypcję do tego odcinka znajdziecie oczywiście na hospoda.tech łamane na 11 od numeru tego odcinka a teraz już przechodzę do.

do konkretów. Nie będę szedł po kolei, tak jak mówiłem, to nie jest w żaden sposób podsumowanie konkretnych, konkretnych prelekcji. Jest to bardziej zebrane wszystko do kupy i to jak ja to widzę, więc jeszcze raz podkreślam subiektywnie, subiektywnie przez Wojtka jest to podsumowywane. Dobra.

Obecne trendy to chyba nikogo nie dziwi. Wiele się mówiło o agentach, wiele się mówiło o MCP, natomiast były też rzeczy, które mnie zaskoczyły. No i bardzo dobrze, bo inaczej jaki byłby sens wlać udział w takiej konferencji. Powoli pojawia się troszeczkę takie, no nie powiem, że odwrót wstecz, natomiast lekkie zastanowienie się nad wszystkim, tak, czyli...

już w tych prelekcjach pojawiały się takie rzeczy, że agent nie jest zawsze najlepszym rozwiązaniem, czy nawet samo AI nie jest do końca najlepszym rozwiązaniem jakiegoś problemu, czyli to simplicity over complexity. I niby z drugiej strony już od dłuższego czasu na LinkedInie chociażby pojawia się to, że...

AI to nie jest strategia firmy i tak wszyscy niby to wiedzą, wszyscy robią, a krytykują i w ogóle no to tutaj z technicznej perspektywy rzeczywiście zaczął się swego rodzaju, no mówię może nie odwrót, a zrozumienie takie i mówienie głośno o tym, że nie zawsze AI, nie zawsze jakieś bardzo przekomplikowane rozwiązania, tylko to...

To ma działać, po prostu i spełniać swoje jakieś swoje zadanie. Przypomniane zostało w ogóle, że mamy jakieś inne AI poza generatywnym AI i tutaj dużo już było używane, że nie AI w domyśle generatywne, tylko generatywne AI i pojęcie tego klasycznego, analitycznego AI, o którym wydaje mi się, że gdzieś jeszcze będę tutaj wspominał.

Natomiast często właśnie jest to dużo lepsze rozwiązanie, zwłaszcza w przypadku enterprise, gdzie ten governance jest istotniejszy, gdzie trzeba wiedzieć więcej troszeczkę co dlaczego się dzieje. No i tam gdzie są takie dane liczbowe, gdzie są tego typu rzeczy, to lepiej jakiś model zaprzągnąć, sobie troszeczkę dotrenować nawet.

aniżeli wszędzie to generatywne, wszędzie te LLM-y. Bardzo ciekawe tutaj podejście do tego, jak wdrażać nowy proces oparty AI w firmie. Ja sam osobiście często, jeżeli mówiłem o jakimkolwiek automatyzowaniu procesów w firmie, czy najpierw rozumieniu tych procesów w firmie po to, żeby je potem zautomatyzować,

Porównywałem sobie ten proces firmowy do tego, jak funkcjonowałoby to rzeczywiście, gdyby to był taki staroświecki urząd, może nie urząd pocztowy, ale po prostu urząd, gdzie jakieś dokumenty, czyli nasze dane krążą od pokoju do pokoju, od urzędnika do urzędnika, czyli od naszych serwisów tutaj i to wszystko w ten sposób można byłoby opisać, no to...

Tutaj mamy podejście, że wdrażając nowy proces AI czy budując go w oparciu ogólnie o AI generatywne, AI tutaj bardziej, powinniśmy naprawdę zastanowić się, gdybyśmy do tego tasku chcieli zatrudnić jakiegoś juniora, człowieka z bardzo małym, czy wręcz bez doświadczenia i tak jak temu juniorowi należałoby te taski wytłumaczyć ten proces, to co ma robić.

Tak powinniśmy ten proces opisać AI i podobno jest to bardzo skuteczna metoda. Kolejny temat. Pojawiły się takie dwa główne, nazwane już trendy, chodzi o to, czy może nie tyle trendy, przepraszam, trendy to za dużo powiedziane. Dwa główne podejścia w budowaniu nowych rozwiązań.

Ponieważ temat już istniejących rozwiązań i dokładania AI to zaraz sobie jeszcze może wspomnimy, natomiast zupełnie nowe rozwiązania, no to mamy podejście buy versus build. Mając na myśli buy, czyli kupowanie tutaj prawie że gotowych rozwiązań z platform cloudowych, gdzie naprawdę nasz udział staje się...

jako dostawcy końcowego, staje się coraz to mniejszy. I tutaj w połączeniu jeszcze z innymi rzeczami, których będę mówił później, ja widzę bardzo duże zagrożenie w przypadku tego podejścia buy. Ponieważ tutaj można zacząć się zastanawiać, co tak naprawdę w tym momencie jest wartością dodaną dla klienta. Jeżeli...

Naprawdę większość, jak nie prawie wszystko w tym naszym rozwiązaniu jest po prostu wykorzystaniem, już nawet nie API tylko skonfigurowaniem sobie tego w naszym panelu zarządzania chmurą. i dobra, podłączenie rzeczywiście gdzieś czegoś koniec końców przez API. Natomiast...

co, dajemy frontend? No to tak, to już powiedzmy sobie jest jakaś wartość, natomiast różnie tutaj z tym bywa, ponieważ tu z tego mojego bloku notatek również mam zapisane takie zaprezentowaną opinię, że nie powinniśmy się przyzwyczajać do kodu, który piszemy, czy do bibliotek, z których korzystamy, ponieważ kod za rok będzie przestarzały.

a bibliotek może nie być, bo to tak wszystko idzie szybko, czy mówiąc już ekstremalnie może prawie że nie być samego kodu. Ja nie byłbym tutaj takim w cudzysłowie optymistą. Jednak to co już też poruszaliśmy w dyskusji chociażby tydzień temu, ja jestem mocno zwolennikiem tego, że OK.

Od AI nie uciekniemy, świat się zmienił już i będzie się zmieniał dalej. Natomiast takiej utopii bez programistów, bez kodu i oczywiście tym samym bez bugów raczej bym nie przewidywał. To tak się nie skończy, to tak nie będzie. Tutaj...

Ja tak samo mógłbym powiedzieć, że nie powinniśmy się przyzwyczajać do tych gotowych serwisów, o które opieramy nasze rozwiązania, ponieważ ich za rok też może nie być. No co jest z tym problemem? Bo jakie są jeszcze zagrożenia w tym baj? No jeżeli się uzależniamy i ktoś nam zacznie podnosić cenę, to z większą ceną za tą usługę nasz...

nasze rozwiązanie przestaje praktycznie istnieć, czy my przestajemy zarabiać, tak? Więc mówię, no okej, ktoś powie, że nie powinniśmy się przyzwyczajać do kodu, do bibliotek, czy nawet istnienia samego kodu, no ja będę mówił bardzo głośno, że nie powinniśmy się uzależniać od gotowych rozwiązań, czyli tak samo po prostu nie powinniśmy się do nich przyzwyczajać. Dzisiaj są, jutro ich może nie być i...

I co jeżeli oprzecie o to swój biznes. Ja już nawet poza IT widziałem takie biznesy, które były oparte o jakiś taki jeden filar i ten filar jak zniknął, to biznes też zniknął. Kolejna sprawa podejście na poziomie enterprise. To też jest ważne, bo co innego startupy, co innego enterprise, czy sam przemysł nawet.

I tutaj takich kilka wniosków żywcem spisanych z tego, co prelegenci mówili. Wszyscy czy duża większość budują, ale mało kto z tej liczby tak naprawdę wdraża nowe rozwiązania oparte o te najnowsze agenty. I nawet jeżeli mówimy tutaj o tych rozwiązaniach wewnętrznych, było podane kilka przykładów rozwiązań, które...

poniosły klęskę, ponieważ na przykład ludzie chociażby nie byli przeszkoleni odpowiednio do korzystania z tego. To nie zawsze, ja nie będę się upierał, że to zawsze jest problem AI i to AI jest złe, bo AI się nie da powiedzmy sobie wdrożyć. Oczywiście rozwiązania nie są jeszcze w 100 procentach prawidłowe, muszą być dalej weryfikowane przez człowieka. To już nie raz też było powtarzane w podcastie.

Natomiast koniec końców R &D jest dobre i ktoś to R &D musi musi tak naprawdę robić. To to nie jest tak, że od razu wpadamy na super ostateczne końcowe rozwiązania, więc ktoś musi dla nas, dla naszego pożytku te błędy popełniać i szukać tych lepszych rozwiązań. Na dzień dzisiejszy konkluzja tutaj

z tego panelu, z tego bloku mogłaby być taka, że wiele więcej można osiągnąć w przemyśle, chociażby z wykorzystaniem klasycznego, analitycznego AI do zarządzania procesami produkcji, czyli to, co jest robione, co było robione, coś, co w dzisiejszych czasach bardziej nazwiemy właśnie uczeniem maszynowym, a nie samym AI.

Natomiast to działa i tu też możemy wrócić do tego, co mówiłem wcześniej, że pojawia się to rozumienie, że AI niekoniecznie jest najlepszym rozwiązaniem, bo czasem może być zbyt skomplikowane. Natomiast druga strona medalu jest taka, że od AI tego generatywnego chociażby już nie uciekniemy. Jeżeli ono się gdzieś nie będzie zupełnie nadawać, no to jedno, ale...

Tak naprawdę w firmach trzeba zacząć o tym AI myśleć, jeżeli się jeszcze nie myśli. AI jest po prostu kolejnym etapem rozwoju w procesie ewolucyjnym rozwiązań software'owych, rozwiązań komputerowych, obliczeniowych. Kiedyś mieliśmy mainframe.

Pojawił się PC i nagle wszyscy mogli zacząć korzystać z komputera na biurku. Potem w latach 90. nadeszła era Excela i wszyscy zobaczyli ile więcej można tak naprawdę wykonywać obliczeń czy jakichś księgowych rzeczy z wykorzystaniem komputera w bardzo szybki sposób jak można.

przygotowywać raporty sprzedażowe, jak można przygotować praktycznie raporty o czymkolwiek. Nadeszła era internetu, już tak no Excel dalej był nam potrzebny, ale mogliśmy się komunikować, mieliśmy dostęp do szerokiej wiedzy, mogliśmy się z kimś dzwonić, wideokonferencję i tak dalej. Następnie przyszedł Cloud, też wszyscy byli nim super zachwyceni.

Co to jest za nowa technologia, wielki skok ewolucyjny i do tej pory wydaje mi się, że przy żadnej z tych, no nie powiem, że rewolucji, ale skoków naprzód nikt się aż tak bardzo nie bał o człowieka i o pracę dla nas. Natomiast po Cloudie przyszło AI, przyszło generatywne AI przede wszystkim. No i tutaj bolimy się o...

o ludzi, o zatrudnienie, ale o tym sobie jeszcze powiemy później. Natomiast ważna rzecz, stare technologie w firmach, nie podążanie do przodu to jest bardzo duże ryzyko, czyli ktoś kto przed erą Eksela, no wiadomo z niego nie korzystał, ale nadszła era Eksela i nie chce z niego korzystać, to sam sobie stwarza ryzyko.

Kolejny tutaj blok, z który chciałem poruszyć, to jest kwestia zmiany podejścia w infrastrukturze. i teraz tak, rzeczy dzieją się w AI na tyle szybko, że już mówimy tutaj o poprzedniej epoce podejścia, która była raptem w 2023 roku.

A mamy rok 2025 w tej chwili, czyli tak naprawdę dwa lata różnicy. A już tutaj żartobliwie zostało to przedstawione, że nasze obecne AI to nie jest your mother's AI, to nie jest już AI naszych rodziców. Wszystko się zmienia i nastąpił pewien, pewna zmiana kierunku. Oczywiście...

To opieram przede wszystkim na prelekcji ludzi zajmujących się infrastrukturą, więc no mogło być to mocno zbajasowane. Natomiast takie kilka przykładów, jeżeli te dwa lata temu wszyscy mówili o serwisa, które można mierzyć, o wynajmowaniu rzeczy na godziny, czy minuty, czy sekundy, to...

Dzisiaj tak naprawdę nastąpiło przesunięcie w kierunku infrastruktury opartej z powrotem o serwery bermetalowe, bo mówi się o tym, ile będziemy mieli stabilnie dostępnej mocy obliczeniowej pod AI, a nie jak szybko jesteśmy w stanie się z pewnymi rzeczami zeskalować. Tak jak mówiło się dwa lata temu o tym właśnie, że

mamy bardzo szeroki dostęp do sieci, jak sieć jest zbudowana, topologie na najwyższym poziomie. No to w dzisiejszych czasach przeszliśmy rzeczywiście na ten bardzo niski poziom i mówi się o tym, jak są budowane specjalistyczne staki pod właśnie AI. No i tutaj...

był taki cytat, że właśnie jeżeli firma jest dosyć duża i jakaś taka prężnie działająca i zajmuje się AI, to na 99 % infrastruktura będzie postawiona na Kubernetesie, który oryginalnie został stworzony od Google'a, to przez Google'a i to już możecie się domyślić, kto tą prelekcję tutaj nam wygłaszał. Rzecz bardzo ważna.

którą ja widzę tutaj ze swojej strony, to następny jak gdyby rozdział, już wchodzimy, to są problemy z jakością. Bardzo dużo mówi się o technologii, o kolejnych nowych technologiach, o dokładaniu kolejnych warstw, jak już na warstwę wielu agentów nakładamy kolejnego agenta, który będzie zarządzał tymi agentami i no...

Tutaj ja nie chcę wchodzić w szczegóły, bo to były konkretne prelekcje, natomiast widzę tu rzeczywiście takie dosyć duże zagrożenie, że to wszystko staje się przekomplikowane. Tu już pomijając nawet, nie powinniśmy pomijać, ale gdzieś tam odstawiając trochę na bok koszty, koszty środowiskowe i tak dalej, to troszeczkę tu...

Z niektórych tych wdrożeń to takie się robi lekko szalone. A koniec końców moim zdaniem zapomina się o jakości. Tutaj wracając do tego co mówiłem przy Enterprise wielu buduje, wielu projektuje, mało kto wdraża bo ta jakość gdzieś ucieka. Są próby testowania tego natomiast

Jeżeli mamy generatywne AI, które nie zawsze nam tak w 100 % to samą odpowiedź da, aczkolwiek odpowiedź może być dalej dobra, ale zupełnie inaczej sformułowana, czy rozpoczęta od jakiejś innego konta ta odpowiedź, no to w tym momencie testowanie jest bardzo dużym wyzwaniem. No i do testowania należałoby tutaj gdzieś zaprząc kolejne AI, czyli...

No tak jak przy innej gdzieś tam prezentacji właśnie było mówione, że AI nam coś szybko wygeneruje, AI zrobi to, AI zrobi tamto, ale AI narobi nam bardzo dużo błędów przy tym i będziemy budować kolejne AI do tego, żeby nam te błędy tych poprzednich AI naprawiało i troszeczkę wchodzimy w takie błędne koło tego AI.

napędzanego przez kolejne AI i AI na AI i w ogóle no tu można byłoby troszeczkę jakoś tak nie wiem zrobić jakiś śmieszny sketch z tego AI. Natomiast dwa fajne cytaty, które są zawsze jak tak wiecie, że skróty tak w IT są zawsze tak mile widziane i lubiane, czyli mamy na przykład dry do not repeat yourself.

I tutaj, jeżeli chodzi o rozwinięcia skrótów, to pamiętajcie, że S w AI oznacza security i tak samo S w MCP oznacza security. Czyli tak troszeczkę tu sarkastycznie. Jest dużo zagrożeń związanych z bezpieczeństwem tych rozwiązań opartych w AI. Ja wiem, że to modele coraz bardziej są zabezpieczane i tak dalej, ale sami wiecie,

jakie były różnego rodzaju problemy z tym, że troszeczkę naokoło z takim czatem się porozmawiało i dało się pewne informacje wydobyć. I tutaj znowu wracamy do tych chociażby trzymania danych na tych bare metalach, a nie w Cloudie. Dobrze, tutaj bardzo ciekawa rzecz. Github, w żaden sposób nie jestem sponsorowany przez...

przez nich, może szkoda. Natomiast ja już też od jakiegoś czasu korzystam rzeczywiście z GitHuba z Copilot nie tylko do tego szybszego, lepszego, bardziej rozbudowanego auto uzupełniania kodu, ale też o kilka więcej funkcji. tutaj koniec końców ilość funkcji mnie mocno zaskoczyła wręcz. GitHub

w tej chwili buduje jak gdyby kompletne środowisko wspierające proces developmentu przez AI. Czyli to już nie są tylko te auto uzupełniania czy ten nowość dla nich tryb agentowy, no bo wiadomo oni muszą gonić za konkurencją. Czyli możemy tutaj już dyktować to co ma zostać napisane.

Natomiast tutaj ta integracja i tutaj zobaczcie znowu to jest bardzo istotne, że tu są jakieś modele i są to powiedzmy sobie dobrze działające modele, ale główną wartością tego produktu jest integracja już z istniejącą platformą. To product ownerzy, product menadżerowie powinniście zapamiętać, bo w GitHubie

możemy sobie wygenerować kod oczywiście, ale możemy go wygenerować na podstawie stworzonych issue w naszych repozytoriach. Jeżeli jest jakiś problem opisany, to po prostu klikamy, żeby na podstawie tego zgłoszonego problemu powstało rozwiązanie kodowe, które oczywiście my potem musimy sprawdzić, przetestować, mieć pewność co wydajemy. Natomiast tutaj mówimy o takich w przypadku tego podejścia

GitHuba, pełnego podejścia wsparcia procesu, mówimy powiedzmy sobie o godzinie zaoszczędzonej dziennie. To nie jest zastąpienie programisty, to nie jest zyskanie połowy czasu, to jest po prostu zyskanie godziny dziennie, ale tą godzinę dziennie możecie sobie już przeliczając na koszty programisty, pomnożyć przez tydzień, pomnożyć przez miesiąc, pomnożyć przez rok.

I tak naprawdę możecie zobaczyć, więcej ten jeden programista, no bo znowu nie idźmy drogą ilu mniej programistów możecie mieć, ale ile więcej ten programista jest w stanie w tym czasie osiągnąć, w tym czasie dowieźć. Tutaj z kolejnych takich funkcji to na przykład wsparcie review kodu poprzez agenta. Z tego też akurat sam korzystam.

zanim jakiś tam mój pull request pójdzie do człowieka do oceny, no to sobie jednym kliknięciem odpalam Copilot, który sprawdza ten kod i jakieś takie pierdółki potrafi tutaj wskazać, że powinny zostać poprawione. Część tych prostszych może poprawić za nas, ale jeżeli ma jakieś takie rzeczy niezrozumiałe też dla niego, to pyta.

Oczywiście wiele z tego w praktyce było błędne, ponieważ miał za mały kontekst, czy nie zrozumiał kontekstu, czy nie wiedział po co to jest. No ale warto obserwować GitHuba i warto się zastanowić, co tak naprawdę możemy wykorzystać i jak usprawnić swój proces. Na co należy zwracać uwagę, ogólnie co śledzić na rynku AI? Pojęcie...

tak zwanego werytykalnego AI, czyli według tutaj pewnej grupy R &D to co mamy w tej chwili to jest AI horyzontalne, które idzie szeroko, ale nie idzie głęboko tak naprawdę i tu nie pomylmy tego z uczeniem głębokim. Przyszłością podobne jest werytykalne AI.

które będzie wchodziło dużo głębiej w temat, które będzie właśnie dokładniejsze, które będzie dawało nam lepsze odpowiedzi. Dla tych, co chcą być na bieżąco, proponuję sobie zapisać pojęcie i śledzić, co się będzie pojawiało. Dobrze, powolutku dopływamy już do jakiegoś takiego końca przed ostatnia sekcja panele.

Tutaj powiem wam szczerze, że miałem takie wrażenie, że po prostu powielały się opinie, które znam, które już wcześniej słyszałem, co też jest jakąś wartością dodaną, ponieważ potwierdza się tylko to, co powiedzmy sobie już wiem, co myślę, ale to też może wynikać z tego, że ja mam jakąś tam głębszą, bardziej zaawansowaną wiedzę i powinienem na brać poprawkę.

Ważna rzecz z panelu, która została wyciągnięta tutaj przeze mnie, to jest to, że jeżeli była rozmowa o zatrudnieniu, wpływie na zatrudnienie, to według przytoczonych informacji tak naprawdę nie ma badań, które potwierdzałyby znaczący wpływ AI na zatrudnienie w IT. I tak naprawdę ja...

Słyszę o przypadkach, gdzie firmy właśnie się pozbywały deweloperów, teraz zatrudniają na nowo. Więc o tym chyba nawet było wspominane tydzień temu w podcastie. Więc ja o przyszłość programistów, dobrych programistów, tych takich programistów z prawdziwego zdarzenia, jestem spokojny. Ktoś to AI musi tworzyć, ktoś to AI musi nadzorować.

Ktoś temu wszystkiemu musi nadawać pewien rytm czy kierunek i to będzie dalej potrzebne, natomiast może być tak, że nie będzie potrzebne dużo, dużo więcej ludzi, więc utrzymamy się na jakimś poziomie tego, co mamy w tej chwili. Ważna rzecz w przypadku tych zagrożeń związanych z zatrudnieniem, to nie AI powinniśmy się obawiać.

tylko powinniśmy się obawiać, że zastąpi nas osoba, która lepiej z tego AI korzysta i o tym się słyszy, że osoby, które nie chciały się dostosować, które nie chciały wdrożyć AI, tam czy to bardziej naturalnie, czy po prostu podziękowano im za współpracę. Ostatni moduł, że tak powiem, ostatnia sekcja, sama konferencja. Tutaj według organizatorów wydarzenie...

albo może wróć jeszcze. Na pewno jest to jedno z większych wydarzeń w Polsce w tematyce. Dwa dni, dużo ciekawych prelekcji, kilka firm wystawiających się poza prelekcjami. to coś, czego, i tutaj włączy się mój lokalny patriotyzm, jest to coś, czego na pewno nam tu w Szczecinie brakuje. Oczywiście...

Jutro już konferencja AI Connect Philharmonii, super, jest, natomiast to wydaje mi się jeszcze nie jest ten poziom, ale zobaczmy, chociaż tu AIBA i AI Connect mają wiele wspólnego, bo są równolatkami, w tym roku obie konferencje

mają trzecią swoją edycję. Obydwu uczestniczyłem rok temu, trzy lata temu nie uczestniczyłem i z tego gdzie mi tam coś się obiło o uszy, to trzy lata temu obie miały raptem dziesięciu prelegentów i były bardzo, bardzo kameralne. No to teraz tutaj taki dzwonek na pobudkę naszego regionu i regionów, które się powiedzmy sobie

Słabiej z tym rozwijają jak to jest, że w Katowicach z 10 prelegentów w 3 lata doszliśmy do 60. Dwóch pełnych dni konferencji i trzeciego dnia na workshopy. Dobrze, już tu nie porównując, przechodząc do samego AIBA 2025, według organizatorów było więcej prelegentów.

Być może nawet było więcej wystawców, bo bardzo ciekawe firmy się wystawiały. Natomiast było więcej więcej i wydaje mi się tak troszeczkę na moje oko było wręcz ich więcej od uczestników. Tutaj akurat taka kwestia, że były różne kolory smyczy, na których nosiło się identyfikatory chociażby, nawet nie tylko różne identyfikatory, więc bardzo łatwo było rozpoznać.

tych ludzi, którzy mieli te czarne dla nas zwykłych użytkowników i jakieś takie błękitne dla prelegentów, organizatorów i tak dalej. Natomiast wpisuje się to ogólnie w taki większy trend, który ja obserwuję w tym roku, odwrotu uczestnictwa w wydarzeniach. Powiem wam, że jasne, ja też wszędzie nie mogę być, chociaż bym chciał być w wielu miejscach i...

Zdarzyło mi się przegapić tutaj nasze szczecińskie małe jakieś eventy. Natomiast widzę, że tak, tych eventów jest na przykład coraz mniej. Tutaj mówiąc o tych małych lokalnych. I nie ma na nich wcale więcej osób, czy jest mniej osób, ale tym zabiegiem właśnie robienia rzadziej organizatorzy ratują się przed tą zmniejszającą się liczbą uczestników.

To jest takie moje, moje gdzieś obserwacja, drugi dzień, słuchajcie, no to było praktycznie pusto już na tej konferencji, więc to tak, no dwa dni konferencji, z czego drugi był zdecydowanie bardziej pusty. Z ciekawostek, translacja, bo konferencja była po angielsku, tak jak rok temu, translacja z angielskiego na polski.

odbywała się poprzez aplikację, którą sobie ściągaliśmy, znaczy odsłuchiwanie tego, poprzez aplikację, którą ściągało się na telefon, czyli nie było już żadnych urządzeń, które pobierało się z recepcji. I ta translacja była wykonywana automatycznie z użyciem AI. No to tutaj moglibyśmy już mówić o wpływie na branżę...

Na branżę tłumaczy, bo jednak były cztery ścieżki, o tym roku o tym zapomniałem powiedzieć, że była jeszcze jedna dodatkowa ścieżka, no bo jeżeli było 60 prelegentów, więcej dużo prelegentów niż w tamtym roku, no to też musiała się pojawić dodatkowa ścieżka, skoro konferencja trwała tyle samo. No ale no to na tych czterech ścieżkach pracy nie znalazło czterech tłumaczy. Istotna rzecz,

którą też wyniosłem z konferencji do zapamiętania, do przemyślenia. I to byłoby na tyle mojego podsumowania. Teraz standardowo dziękuję wszystkim, którzy dotarli aż tutaj pół godziny ponad mówienia solo, no to na pewno może zmęczyć słuchacza. Co za tydzień? Za tydzień mam nadzieję, że podsumowanie konferencji E-Kone, która jak już wspominałem,

Odbędzie się już jutro, czyli 15 października 2025. Jeśli nie, to na pewno mam dla was inne tematy związane z AI. Tak, w hospoda tech teraz mówimy tylko o AI, ale jest to gorący temat i chcąc nie chcąc trzeba o nim również mówić, bo staramy się o nim mówić z zupełnie innej perspektywy. Przypominam, że...

To był, to jest jedenasty odcinek podcastu, czyli jeżeli chcecie zobaczyć transkrypcję, ewentualne linki do tego odcinka, to zapraszam na stronę hospoda.tech łamany na 11. Natomiast jeśli jeszcze nie subskrybujecie, a jesteście ciekawi,

Co będzie dalej w podcaście, to zachęcam do zasubskrybowania podcastu w aplikacji, której go w tej chwili słuchacie. Jeśli jest taka możliwość, dajcie lajka, zostawcie komentarz lub wystawcie ocenę. To się różni w zależności od aplikacji. Wiem, tam gdzie się da, miło by było, gdybyście to zrobili. Na pewno będzie to dla mnie duża motywacja do dalszego tworzenia tego podcastu. Tutaj tak trochę...

z takiego backstage'u, powolutku, powolutku grono słuchaczy rośnie. To jest 11 odcinek, czyli mamy 11 tygodni publikowania. Nie jest was jeszcze dużo, ale gdzieś to wszystko zaczyna się ruszać z miejsca, co mnie niezmiernie cieszy. Jeżeli chodzi jeszcze o social media, tak tylko wspomnę, możecie się również zapisać do newslettera. Tam też będziecie informowani o

wydaniu kolejnego odcinka, może z lekkim opóźnieniem. Mam nadzieję, że jak tylko znajdę czas, rzeczywiście w tym newsletterze zacznie się też jeszcze troszeczkę więcej innych rzeczy pojawiać. Znajdziecie oczywiście newsletter na stronie podcastu, czyli hospoda.tech. Możecie znaleźć mnie czy też podcast na Facebooku, iksie lub blue sky up. Ja dziękuję za dzisiaj i...

Do usłyszenia za tydzień.
