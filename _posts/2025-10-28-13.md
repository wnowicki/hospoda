---
title: AI a Prawo
layout: post
subtitle: AI a Prawo rozmowa z mec. Rafałem Malujdą
description: Sztuczna inteligencja coraz śmielej wkracza do kancelarii, sądów i urzędów. Czy prawnicy powinni się obawiać, że zastąpią ich algorytmy? Jak prawo nadąża za technologią, która sama zaczyna pisać umowy i analizy prawne?
date: 2025-10-28 19:00
author: wojtek
spotify:
  id: 1VBBWBNm8JOCCThziIMLCV
  url: https://open.spotify.com/episode/1VBBWBNm8JOCCThziIMLCV?si=23p8DsmCTUSrDQvSQLclrQ
apple:
  url:
youtube:
  url:
categories:
  - rozmowy
tags:
  - AI
  - prawo
host: wnowicki
people:
  - rmalujda
toc: false
---

## Transkrypcja

> Transkrypcja jest generowana automatycznie

Rafał (00:05)
Sztuczna inteligencja zaczyna komponować projekty pism, projekty umów, ale coś, co jest teraz wartością dodaną i z tego jak ja obserwuję ten rynek, to faktycznie jest to jakiegoś rodzaju nowum. Możemy trochę zaczynać programować pisma i umowy.

Wojtek (00:46)
Zapraszam na 13 szczęśliwy odcinek podcastu hospoda.tech. Dlaczego szczęśliwy? O tym powiem wam na końcu odcinka. Dzisiejszym moim gościem jest Rafał Malujda, radca prawny i rzecznik patentowy. Zajmuje się w szczególności ochroną własności intelektualnej RODO, Fintechami e-commerce. Z Rafałem porozmawiamy o tym, jak prawnicy patrzą na sztuczną inteligencję, jakie widzą w niej zagrożenia, szanse i wyzwania.

a także o tym jak AI zmienia branżę prawniczą od środka. Transkrypcje, linki i wszelkie materiały do tego odcinka znajdziecie na hospoda.tech łamany na 13. Zachęcam do subskrybowania podcastu, dzięki temu nie przegapisz kolejnego odcinka. A teraz już zapraszam na dzisiaj i życzę miłego słuchania.

Wojtek (01:42)
Cześć Rafał, witam w podcaście.

Rafał (01:44)
Cześć Wojciechu!

Wojtek (01:46)
Pierwsze pytanie, jak prawo obecnie definiuje sztuczną inteligencję? Czy w ogóle mamy w tym zakresie spójne podejście legislacyjne pomiędzy Unią Europejską, a resztą świata?

Rafał (01:56)
W Unii Europejskiej to jest dobry rok, żeby rozmawiać o sztucznej inteligencji z tego względu, że w dużym zakresie rozpoczęliśmy stosować AI Act w 2025 roku, który zabiera definicję systemu sztucznej inteligencji, definiuje też jakiego rodzaju modele sztucznej inteligencji.

takiego rodzaju swoisty backend tego, co systemy sztucznej inteligencji obrabiają, czym się zajmują, jest w nich wykorzystywane. Także na poziomie Unii Europejskiej mamy jakiegoś rodzaju punkt wyjściowy, mamy jakiegoś rodzaju jednolitość. W innych rejonach świata prace legislacyjne trwają albo są w planach, albo gdzieś tam dopiero się rozpoczynają.

Dlatego też ciężko jest mówić o jakimś globalnym czy międzynarodowym spójnym podejściu, ale wydaje mi się, że jesteśmy już na tym etapie dojrzałości, że mówimy o tym samym. Rozróżniamy przede wszystkim systemy od modeli sztucznej inteligencji. Wiemy, sztuczne, że modele sztucznej inteligencji to modele, które albo z jednej strony mają mieć charakter predykcyjny, czyli na...

na bazie jakiegoś rodzaju danych historycznych mają dokonywać predykcji czy to wyników, czy jakich zdarzeń w przyszłości. ich podwaliną są modele statystyczne czy uczenie maszynowe. Z drugiej strony mamy do czynienia z generatywną sztuczną inteligencją, z czymś, co wydaje mi się taki przeciętny użytkownik Internetu ma na dzień dzisiejszy najczęściej styk.

czyli różnego rodzaju narzędzia w postaci czata, GPT, dali, kopilota chociażby. Mówimy tutaj o narzędziach, które wytwarzają różnego rodzaju treści, niezależnie czy to jest grafika, muzyka czy tekst. I podstawą podwaliną są różnego rodzaju duże modele językowe. Coraz więcej też wiemy o tych modelach, coraz więcej wiemy jak one...

działają i to wydaje mi się, że jest bardzo istotne, czyli idziemy w tym kierunku coraz większej transparentności, już niezależnie od tego, czy konieczność ich wprowadzenia wynika z przepisów prawa, czy wynika z tego, że rynek się musi dopasować do zmieniającej się rzeczywistości i dostarczać użytkownikowi coraz więcej danych, to wydaje mi się, że to jest jakiś wspólny mianownik, że rzeczywiście już wiemy, że jest ta sztuczna inteligencja. Na początku wiedzieliśmy, że

czy też mówiono nam, mówiono nam jakoś w cudzysłowie przeciętnym użytkownikom, że niewiele możemy wiedzieć o tych obliczeniach, operacjach, które się w tej sztucznej inteligencji odbywają, co wydaje mi się, że było trochę takim unikiem ze strony dostawców niż tym, co rzeczywiście można o tych narzędziach powiedzieć, bo też nie można zapominać o tym, że teraz mówimy o sztucznej inteligencji. Wcześniej mówiliśmy o uczeniu maszynowym.

odkryli historię hasła, sztuczna inteligencja na Wikipedii, lata temu to było po prostu uczenie maszynowe. I wtedy to uczenie maszynowe było modne. Wielu dostawców IT ówcześnie reklamowało każdy swój produkt, szczególnie konsultingowy, że on też jest...

wspierany uczeniem maszynowym. Teraz już uczenie maszynowe nie jest aż tak trendy, jeżeli chodzi o marketing w IT. No to wszyscy się przesiadamy, czy przesiedli na sztuczną inteligencję.

Wojtek (05:53)
Tak jak wspomniałeś, tak ogólnie sztuczna inteligencja nie jest zagadnieniem nowym, jest to rok chyba 1954, wspominałem już o tym w poprzednich odcinkach, ale tak samo kilkukrotnie już na łamach tego podcastu poruszałem kwestię odpowiedzialności za działanie AI. Czy to będziemy mieli AI predykcyjną, czy tą generatywną, zwłaszcza ta predykcyjna wspiera podejmowanie pewnych decyzji, ale dalej

Ta decyzja jest podjęta przez człowieka i człowiek bierze za nią odpowiedzialność. Tutaj pojawia się pytanie, czy potrzebne będzie stworzenie nowych kategorii prawnych, na przykład osobowości prawnej dla sztucznej inteligencji, gdzie tak naprawdę kończy się pomoc AI, a gdzie zaczyna odpowiedzialność człowieka. I tak jak już ty wspominałeś o transparentności modeli, to czy ta transparentność powinna być ważniejsza, czy jednak...

odpowiedzialność użytkownika i tu pytam w kontekście zarówno tej AI predykcyjnej jak i generatywnej, tam zakres, znaczy co za co odpowiadamy będzie różny.

Rafał (07:04)
to wydaje mi się, odpowiedź na to pytanie będzie zależała od tego, na co ludzie sztucznej inteligencji pozwolą. Czyli jeżeli ludzie, czyli my, na dobrą sprawę, pozwolimy na to, żeby sztuczna inteligencja nie tylko rekomendowała decyzje, ale też je implementowała bez jakiegoś rodzaju weryfikacji człowieka,

no to faktycznie będziemy mówili tutaj o konieczności wprowadzenia jakichś reguł dotyczących odpowiedzialności i takim dobrym obszarem do potestowania tego, czy też konieczności wprowadzenia tego są tak na dobrą sprawę, sprawę pojazdy autonomiczne, czy różnego rodzaju autonomiczne środki lokomocji, gdzie tak na dobrą sprawę to podejmowanie decyzji

zamiast człowieka już się dzieje. wracając do ogólnych kategorii prawnych, ta decyzja będzie musiała być przypisana do jakiegoś organizmu istniejącego. Na dzień dzisiejszy, przynajmniej jeżeli chodzi o prawodawstwo polskie, wielu innych państw europejskich, mamy dwie albo trzy kategorie prawne. Mamy osoby fizyczne, mamy osoby prawne i tak zwane, jak to mówią prawnicy, ułomne osoby prawne.

powszechnie używana w języku prawniczym, czyli takie nie do końca osoby prawne, ale już nie osoby fizyczne. Niezależnie od tego, czy mówimy o osobach fizycznych czy o osobach prawnych, to są to organizmy, które funkcjonują. Możemy odpowiedzialność tym organizmom przypisać, bo tak się umówiliśmy, jeżeli chodzi o przepisy prawne.

prawne w rzeczywistości nie istnieją, jednak osoby fizyczne wprawiają te osoby wprawne w ruch, idą do notariusza, zakładają chociażby spółkę z ograniczoną odpowiedzialnością. I ten byt na papierze jest przypisywalny określonym osobom fizycznym, czy to funkcjonującym w zarządzie, czy działającym po stronie wspólników, czy beneficjentów rzeczywistych.

I tutaj te reguły odpowiedzialności są przypisane do konkretnego podmiotu. Jeżeli nałożymy na to siatkę, a wydaje mi się, że nie unikniemy tego siatkę AI Actu, to niezależnie od tego, że mamy do czynienia z systemami sztucznej inteligencji, to odpowiedzialność za działanie określonych systemów w tym obszarze, czy określonych modeli jest przypisywalna do producentów tych...

tych narzędzi. I wydaje mi się, że znowu, jeżeli dopuścimy, czy dopuszczona zostanie takiego rodzaju ścieżka, że chociażby w przypadku systemów wspomagania decyzji nawigacyjnych zostanie podjęta decyzja, że w tych przypadkach nie będziemy już mówili tylko o wspomaganiu decyzji, ale podejmowaniu decyzji w zamian

czy w miejsce navigatora, w miejsce kapitana statku, nadal jakiegoś rodzaju podmiot prawny, jakiegoś rodzaju już istniejąca osobowość prawna będzie za to odpowiadała. Na ten moment ciężko jest sobie wyobrazić, żeby była tak na dobrą sprawę konieczność do tego, żeby generować czy tworzyć jakiegoś rodzaju nową osobowość prawną sztucznej inteligencji, bo wydaje mi się, że system prawny jest na tyle akurat tutaj spójnie ułożony, że i tak...

będziemy chcieli przypisać tę odpowiedzialność, czy to do konkretnego Kowalskiego jako do osoby fizycznej, być może prowadzącej działalność gospodarczą, albo do konkretnego organizmu w rodzaju spółki z ograniczoną odpowiedzialnością czy akcyjnej. Także w tym kierunku wydaje mi się, że to i tak już idzie, patrząc na to, co zostało wprowadzone na poziomie AIA.

Wojtek (11:19)
poruszyłeś jeden z moich ulubionych przykładów, pojazdy autonomiczne, czy to samochody, czy to statki, drony. Drugi taki przykład, który zawsze przytaczam, czy to w dyskusjach, czy to o studentom, czy w biznesie, to liczenie ryzyka kredytowego i podejmowanie decyzji kredytowej. Z tym miałem styczność zawodową już 10 lat temu. Natomiast wracając do samych, do samych pojazdów.

jeżeli mamy ten pojazd autonomiczny, żeby on się upowszechnił trzeba będzie wprowadzić jakieś regulacje, no bo nie wyobrażam sobie i tutaj będę musiał dokończyć tą pełną myśl tego, że producent, załóżmy tego oprogramowania, tak po prostu odpowiada za wszystko, jeżeli chodzi o odpowiedzialność za spowodowane wypadki, szkody, jakieś tam uszczerbki na zdrowiu czy śmierci, będą musiały być jakieś regulacje, no bo to tak jak

hamulcami samochodowymi. Hamulce w samochodzie się zużywają, ale po to mamy wprowadzone pewne zasady, pewne ramy. Tak musimy jeździć na przeglądy ze starszymi samochodami już co roku, gdzie siła hamowania jest sprawdzana. I jeżeli spowodujemy wypadek, znaczy jeżeli stanie nam się wypadek i będziemy mieli te hamulce niesprawne, no to wiadomo,

Ty to pewnie lepiej wiesz, pociągnie się cała lawina tego, że zostanie sprawdzone jaki był stan techniczny tego samochodu, kiedy to była sprawdzane i w ogóle czy tam były odpowiednie hamulce, tak samo będzie pewnie powiedzmy sobie z algorytmem, jeżeli stworzymy jakiś algorytm lepszy, gorszy, to będzie trzeba go w jakiś sposób aktualizować i...

No mówię, no ja nie wyobrażam sobie, że tak jak producent hamulców odpowiadałby tak po prostu za niesprawne hamulce w czyimś samochodzie, to producent tego oprogramowania do autonomicznej jazdy będzie odperał za każdy wypadek samochodu.

Rafał (13:15)
Tak, jak najbardziej jest to słuszne spostrzeżenie. I tutaj rzeczywiście producenci systemów sztucznej inteligencji, które już są dopuszczane do różnego rodzaju pojazdów, nie mogą ponosić odpowiedzialności absolutnej za wszystko, co w tym pojeździe się wydarzy. I teraz wydaje mi się, że tutaj są istotne dwie rzeczy.

Po pierwsze, my już dzisiaj korzystamy z urządzeń, zabawek, urządzeń medycznych, w których jest oprogramowanie. Rynek już do tego fenomenu w cudzysłowie przywył. To znaczy, jeżeli mamy rozrusznik serca, którego istotnym elementem jest oprogramowanie, to znane są bardzo rygorystyczne ścieżki dopuszczania takiego produktu do rynku, rynek, zarówno w Stanach Zjednoczonych, jak i w Europie.

I mamy przetrenowane, to jest też zakorzenione na poziomie różnego rodzaju standardów norm ISO, mamy przewidziane ścieżki, co się dzieje w sytuacji, to oprogramowanie ulega aktualizacji. I wiemy, których sytuacjach musimy ponownie dokonać recertyfikacji oprogramowania, zgłosić to regulatorowi, być może poczekać na jego zgodę po to, przed wypuszczeniem kolejnej wersji oprogramowania...

to oprogramowanie mogło obsługiwać funkcjonujące urządzenia, niezależnie, czy to jest zabawka, rozróżnik serca, czy inne narzędzie, inne urządzenie, w zależności od kontekstu może bardzo mocno wpłynąć na sytuację danego człowieka. Teraz jeżeli mówimy o systemach sztucznej inteligencji, to to będzie z tej perspektywy patrząc kolejnego rodzaju oprogramowanie. Już teraz podnosi się

W dyskusjach dotyczących tego wątku, szczególnie właśnie w przypadku oprogramowania medycznego, regulatorzy i rynek idzie w tym kierunku i w branży automotive będzie w mojej ocenie identycznie, regulatorzy będą mieli prawo nie tylko nadzorować to, co jest dopuszczane na rynek, ale w przypadku tych systemów sztucznej inteligencji prosić o wgląd w kod źródłowy oprogramowania, który wprawia w ruch.

model wprawia w ruch system sztucznej inteligencji. Czyli producenci będą musieli się przygotować do tego elementu. To, co jest istotne w przypadku systemów sztucznej inteligencji, to jest czystość, pewność, transparentność danych, na podstawie których ten system, czy ten model bardziej w tym przypadku, działa i funkcjonuje. I to jest, wydaje mi się, nowum, które zaczyna funkcjonować w naszej rzeczywistości.

prawno-regulacyjnej, gdzie dostawcy tego rodzaju systemów będą musieli być gotowi, żeby pokazać dane, jakich ten ich system bazował na danych wejściowych. Z tym może być problem z tego, co się podnosi w praktyce, gdyż wielokrotnie systemy nawet dużych dostawców bazują na zbiorach danych, które nie są u nich zlokalizowane, tylko są zlokalizowane u jakiegoś dalszego dostawcy.

musimy się przygotować do tego, żeby rzeczywiście jako dostawca takiego rodzaju systemu w odpowiedni sposób się zabezpieczyć, czyli zagwarantować sobie prawo dostępu do tych raw data, danych rzeczywistych, od których nasz system co najmniej zaczynał swoją przygodę, jeżeli chodzi o obsługę danego narzędzia. I to jest jeden element. Czyli tu wydaje mi się, że możemy wyjaśnić...

i powiedzieć słuchaczom, tak na dobrą sprawę z tej perspektywy, trochę może nie trywializując, ale próbując uszeregować te kategorie, na dzień dzisiejszy oprogramowanie sztucznej inteligencja w urządzeniach rzeczywistych już jest. I teraz idąc dalej, mamy reguły odpowiedzialności za produkt niebezpieczny, za produkt wadliwy i jesteśmy w stanie zdiagnozować, kto odpowiada.

za wady czy za skutki negatywnego działania danej zabawki, jeżeli nie zadziałało chociażby oprogramowanie i dziecko się poparzyło, bo to oprogramowanie nie zadziałało tak, powinno. I tutaj, znowu, próbując znaleźć punkty odniesienia, to trochę tak jak na budowie. Mamy wiele ekip, wiele instalacji, natomiast pomimo tego, że w praktyce ciężko jest niekiedy...

odnaleźć winowajce danego zdarzenia, to jednak w większości przypadków jest to możliwe, z tego względu, że za branżę elektryczną odpowiada elektryk, hydraulik odpowiada za swoje systemy, architekt spaja wszystko z całości od strony konstrukcyjnej. Natomiast to, co może zdecydować o takim...

w kierunku odpowiedzialności w stronę producenta tych systemów czy producentów samochodów, którzy wprowadzają te samochody na rynek i to będzie jakiegoś rodzaju nową w mojej ocenie trochę w kategorii tej osobowości prawnej, o którą pytałeś w jednym z poprzednich pytań, to będzie kwestia poziomu tej autonomiczności tych pojazdów, której dojdziemy i

tego, od którego momentu człowiek już nie będzie miał absolutnie wpływu na działanie tego samochodu, nie będzie miał od strony i faktycznej i od strony obowiązku weryfikowania czy obowiązku nadzoru nad tym, co się dzieje, oczywiście jeżeli ma taką możliwość. I wydaje mi się, że w przypadku tych najbardziej zaawansowanych systemów, tam, gdzie rzeczywiście udział człowieka już nawet

nie będzie zbędny, on będzie niemożliwy od strony technicznej, to w tych przypadkach te reguły odpowiedzialności będą musiały ulec zmianie i producenci podmioty wprowadzające tego rodzaju dobro, pojazd na rynek będą odpowiadały za całokształt działania. Ale znowu, w pojeździe wprawianym w ruch za pomocą narzędzi sztucznej inteligencji

za pomocą systemów nawigacyjnych, które w danym pojaździe będą funkcjonowały. Winowajcą będzie producent opony, bo ona pęknie nie w tym momencie, w którym powinna. to wtedy też reguły odpowiedzialności już te konwencjonalne, funkcjonujące na dzień dzisiejszy sobie doskonale z takim przypadkiem poradzą.

Wojtek (20:18)
Z tego co mówisz, są te ograniczenia odpowiedzialności, ogólnie też jak kupujemy cokolwiek, to zgadzamy się na ten terms and conditions, czyli warunki użytkowania danego urządzenia, które definiują odpowiedzialności, natomiast jeżeli tak...

No abstrakcyjnie troszeczkę, bo do tego to może jeszcze dużo czasu upłynąć, ale jeżeli wszystko zostanie jak gdyby spełnione, a po prostu jakieś warunki nie zagrają, to w przypadku wypadku takiego samochodu autonomicznego może być tak, że nikt za to nie odpowie.

Rafał (21:01)
I mam nadzieję i na dzień dzisiejszy tak jest, że system prawny do tego nie dopuści i nie dopuszczą też do tego ubezpieczyciele. Na szczęście jest to rynek, niezależnie o jakiego rodzaju pojazdach mówimy, mocno obwarowany ubezpieczeniami obowiązkowymi, niezależnie czy są to pojazdy drogowe, czy wodne, czy drony.

czy w ogóle pojazdy lotnicze. I tutaj ten rynek ubezpieczeń i segment ubezpieczeń na pewno też te wszystkie wątpliwości zaadresuje. Czyli tutaj na pewno nie będzie tak, że nikt nie będzie odpowiedzialny. Aczkolwiek też zdarzało się w orzeczeniach Izby Morskiej, to jest taka działka może bardzo

przyziemna z perspektywy naszej dyskusji, ale zdarzały się sytuacje, gdzie w orzeczenia Hiszpomorskiej, która miała decydować o winie tak na dobrą sprawę o tym, kto zawinił w danym przypadku jakiejś kolizji, to zdarzały się orzeczenia, w których Hiszpomorska stwierdzała, że do danego zdarzenia, do danej kolizji doszło w skutek złych warunków atmosferycznych. I wtedy rzeczywiście

Kapitan nie mógł być pociągnięty do odpowiedzialności, ale mimo wszystko, jeżeli statek wprawiany w ruch przez określone przedsiębiorstwo wyrządził szkodę innemu podmiotowi, to nawet jeżeli nie mogliśmy przypisać wtedy winy kapitanowi, bo ciężko było ustalić, czy rzeczywiście te warunki były na tyle zaskakujące, że ciężko byłoby...

przypisać kapitanowi czy nawigatorowi błędną decyzję nawigacyjną. Z drugiej strony nie mieliśmy do czynienia z sytuacją, że tor wodny chociażby nie był należycie oświetlony czy należycie przygotowany do żeglugi. To nawet w przypadkach ja jako podmiot, który korzystam z danego pojazdu w tym momencie autonomicznego wyrządzę komuś szkodę, to jeżeli konkretny...

człowiek nie będzie mógł być za to odpowiedzialny, to czy właściciel pojazdu, czy podmiot wprowadzający na rynek taki pojazd będzie musiał być odpowiedzialny za takie zdarzenie i przepisy prawne na pewno to zdefiniują.

Wojtek (23:35)
To tak tutaj się w pełni zgodzę jeżeli chodzi o odpowiedzialność tą finansową jakieś zadość uczynienie za wyrządzone szkody to oczywiście jak najbardziej tak jak powiedziałeś ten rynek ubezpieczeń i powiem ci że że świetny ten przykład z tą z tą izbą morską rzeczywiście ja też troszeczkę o tym słyszałem bo akurat już na emeryturze mój dziadek był ławnikiem w izbie morskiej więc trochę tych gdzieś tam opowieści jak to.

jak to się działo, jak byłem młodszy to słyszałem i to jest właśnie ten przykład w sumie, który pytałem w tym poprzednim pytaniu, czyli to zadość uczynienie będzie, bo będzie ubezpieczenie, ale koniec końców warunki będą takie, że ani się algorytm nie pomylił, ani hamulce nie zawiodły, prędkość była powiedzmy sobie dostosowana, ale faktycznie ten lud się pojawił na drodze.

Rafał (24:34)
Tak i to też nie będzie nic niecodziennego, bo my już teraz często mamy do czynienia z różnego rodzaju dysfunkcjami systemów, pojazdów, jakichkolwiek innych urządzeń, które funkcjonują w rzeczywistości. Często ciężko jest stwierdzić, co było przyczyną danej dysfunkcji i regresowo, czyli w przypadku tej wtórnej odpowiedzialności, ciężko jest nam zdiagnozować, czy rzeczywiście na przykład...

producent ogumienia, producent jakichś podzespołów, śrubek, nakrętek, czegokolwiek innego wrażliwego, odpornego albo nieodpornego na wstrząsy, na prędkości, na ilość obrotów, być może nie dopełnił swoich obowiązków, ale po to na szczęście są właśnie później te reguły ogólne, żeby rzeczywiście od strony finansowej, tak jak słusznie zauważyłeś,

mieć zabezpieczony rynek i zabezpieczonych uczestników takich kolizji, takich zdarzeń, nie było rzeczywiście tak, że wszyscy rozłożą ręce i powiedzą, no pojazd autonomiczny, wszystko zadziałało dobrze, no a to, że doszło do kraksy, no to tak się zdarza. No to rzeczywiście do takiej sytuacji rynek na pewno nie dopuści, ale wydaje mi się też i chyba to musimy przyjąć jako element

i naturalne czy natywne tego rodzaju systemów, że mogą być sytuacje, których my najzwyczajniej w świecie po prostu nie dowiemy się, dlaczego coś nie zadziałało i gdzie faktycznie leży wina, czyli już nawet nie odpowiedzialność, ale wina, czyli co było przyczyną. Tak jak powiedziałem na początku, rynek i regulacje prawne idą w kierunku tej transparentności, ale z natury rzeczy

Wszystkiego punktowo, atomowo, tak jakbyśmy chcieli, pewnie w tego rodzaju sytuacjach, my najzwyczajniej w świecie się nie dowiemy. Tak samo jak nie możemy zagwarantować, czy w przypadku generowania treści, korzystania z generatywnej sztucznej inteligencji, dojdzie do naruszenia praw autorskich jakiegoś innego podmiotu, czy też nie, tak samo może być to...

trudne w tych przypadkach, o których ty mów.

Wojtek (27:01)
Ok, super. Teraz przejdę już sobie powoli do AI Act i tych konkretnych regulacji, Bo tak jak powiedziałeś, w tym roku dużo się o tym mówi. Wszyscy zaczęliśmy się w firmach IT zastanawiać, na ile to nas dotknie. Ja będąc na jakichś spotkaniach, gdzie tak powierzchownie tłumaczono nam czym AI Act jest tak naprawdę, no to...

To nie jest to takie straszne przynajmniej z mojej perspektywy, natomiast pytanie do ciebie jako do eksperta, jakie konkretnie zmiany wprowadza nam AI Act, które będą najbardziej odczuwalne dla firm technologicznych przede wszystkim. I czy AI Act realnie zwiększy bezpieczeństwo i zaufanie do AI, czy może przy tym spowolni nam innowacje.

Jakie na dzień dzisiejszy widzisz luki prawne, które są najważniejsze do załatania w przypadku AI i czy AI Act je domyka?

Rafał (28:00)
AI Act jest konstrukcją, która w mojej ocenie przynajmniej dobrze, że się pojawiła w naszej rzeczywistości prawnoregulacyjnej i on faktycznie wprowadza kilka nowości. Nie jest to...

dzieło czy regulacja skończona. Czekamy na różnego rodzaju standardy branżowe, na różnego rodzaju wytyczne, które będą doprecyzowały regulacje w AI Act zawarte i tego rodzaju wytyczne one już się pojawiają. Natomiast jeżeli chodzi o taką kategoryzację, to wydaje mi się, że i oczywiście to też się podnosi, że diabeł tkwi w szczegółach

Ale mimo wszystko AI Act zaczyna porządkować cały ten rynek i ten obszar. Wprowadza przede wszystkim pojęcie zakazanych praktyk w obszarze sztucznej inteligencji. Czyli będziemy mieli do czynienia, czy mamy już do czynienia i to są regulacje, które weszły w życie najszybciej.

z praktykami, w ogóle na rynku nie mogą zaistnieć. Tutaj mówimy o systemach, które stosują techniki podprogowe, które wpływają w sposób podświadomy na podejmowanie decyzji przez określone osoby, co może być związane z przykładem, który ty powiedziałaś.

tych decyzji kredytowych czy ogóle namawiania na kredyt przez różnego rodzaju agentów, mówię tutaj o agentów sztucznej inteligencji. Nie można wykorzystywać słabości osoby fizycznej, nierówno traktować użytkowników, dyskryminować, a systemi sztucznej inteligencji mają i to się podnosi z perspektywy zderzenia.

systemów sztucznej inteligencji z jakimiś prawami podstawowymi, poza naruszeniem prywatności, bo to w tej dyskusji się przewiera na porządku dziennym, natomiast rzeczywiście jeżeli mówimy o prawach podstawowych, to systemy sztucznej inteligencji mają dużą łatwość do tego, żeby dyskryminować, żeby naruszać prawa osób w tym obszarze, bo mogą sobie kategoryzować osoby określone preferować,

określonym kategoriom osób, chociażby nie udzielać decyzji kredytowych albo nie brać pod uwagę w jakichś określonych sytuacjach i dlatego z tej perspektywy to dobrze, że AI Act wprowadził tą grupę systemów zakazanych. Drugi poziom to są systemy dużego ryzyka i grob przepisów AI Actów dotyczy tego rodzaju rozwiązań, one są...

doprecyzowane czy też wylistowane jako przykładowe kategorie w jednym z załączników do AI Actu. i tutaj tych systemów dużego ryzyka, trochę można powiedzieć są na pograniczu z tymi systemami czy też z praktykami zakazanymi. Jest dość sporo. No i tutaj w przypadku chociażby kształcenia i szkolenia zawodowego, jako przykład podaje się

jako przykład tego systemu wysokiego ryzyka, systemy sztucznej inteligencji przeznaczone do wykorzystywania, do celów podejmowania decyzji o dostępie lub przyjęciu do instytucji edukacyjnych i instytucji szkolenia zawodowego. I tych przykładów jest oczywiście dziesiąt, jeżeli chodzi o poziom AI aktu. I z tej perspektywy to też istotne i dobre, że w stosunku do tego rodzaju...

systemów, które będą wpływały najzwyczajniej w świecie na nasze życie, bo albo dostaniemy, albo nie dostaniemy kredyt, albo zostaniemy, albo nie zostaniemy przyjęci do określonej instytucji edukacyjnej, no to z tej perspektywy jest to szalenie istotne, że ten obszar został uregulowany. Kolejny poziom to są systemy sztucznej inteligencji w stosunku do których ustawodawca nałożył na

na podmioty wprowadzające na rynek tego rodzaju rozwiązania obowiązki transparentności. No wszelkie pozostałe systemy, w stosunku do których nie ma praktycznie żadnych obowiązków, ale które są zachęcane do tego, czy producenci są zachęcani do tego, aby te wytyczne branżowe standardy branżowe wprowadzane przez AIA, które również były stosowane.

Wojtek (33:07)
w kwestii tej dyskryminacji nie wiem czy do końca bym się zgodził znaczy w sensie AI może dyskryminować pewne grupy społeczne chociażby ale z drugiej strony jako że to jest tylko algorytm możemy mu tej

tej dyskryminacji zakazać i na pewno wrócę do tego jeszcze w późniejszych pytaniach, ponieważ mam takie pytanie o twoją branżę i o przyszłość twojej branży. Mnie na pewno z tego co wiem właśnie o AI ACCIE, co powiedziałeś z tych poziomów cieszy to, że AI nie będzie podejmować żadnych decyzji o naszym rozwoju, kształceniu, rozwoju zawodowym.

i tak dalej, że to jest zakazane, tak, więc mam nadzieję, że tutaj to zaufanie do AI zostanie znacząco zwiększone. Natomiast właśnie AI, to tak wy jako branża legal macie podobnie jak my, z jednej strony pracujecie nad AI, my pracujemy nad jej rozwojem technicznym, wy pracujecie nad jej rozwojem prawnym, tym jak to...

zamknąć w jakichś takich bezpiecznych ramach. Natomiast tak samo i wy i my podlegamy również tej rewolucji AI. Czy mógłbyś nam troszeczkę przybliżyć jakieś przykłady wykorzystania AI w praktyce już u was, w waszej branży?

Rafał (34:37)
Tak, najbardziej.

Jak najbardziej. Często zwykło się żartować, że AI zastąpi prawników, programistów i co najmniej kilka innych grup zawodowych i to, AI może wprowadzić, jeżeli chodzi o ten rynek, to wydaje mi się, że może utrudnić dostęp czy...

utrudnić rozkręcenie się młodszym kolegom i koleżankom po fachu w tym obszarze, bo klienci będą najzwyczajniej w świecie przekonani, że mogą prostsze czynności, czy prostsze zadania wykonywać sami. Niezależnie, czy to będzie słuszna, czy nie słuszna ocena, to rzeczywiście w tym kierunku może to iść.

Jeżeli chodzi zaś o te praktyczne zastosowania, to przede wszystkim analiza dużych zbiorów danych, co może jest trywialną konstatacją, ale w branży prawniczej szalenie mocno ułatwia to działanie. Mówię tutaj o przejrzeniu zarówno zasobów zewnętrznych, niezależnie jaką bazę do danego narzędzia podepniemy, jak i zasobów wewnętrznych kancelarii.

o których często wraz z upływem czasu najzwyczajniej w świecie można zapomnieć. Wiele kancelarii, wielu prawników ma dość pokaźny dorobek. Nie mówię tutaj o korzystaniu z danych konkretnych klientów, tylko ma wypracowane różnego rodzaju klauzule, typy klauzul, formuły dokumentów, które można doskonale reużywać. Co zresztą każdy specjalista w różnych branżach

z powodzeniem realizuje i z upływem lat w przypadku, gdy w kancelarii, na pokładzie kancelarii jest kilku, kilkunastu i półdziesięciu prawników, no to te narzędzia są najzwyczajniej w świecie bezcenne, bo nie jest to zwykła wyszukiwarka, z jaką mieliśmy do czynienia jeszcze x lat temu, a narzędzie, które potrafi samo coraz lepiej, mówiąc wprost, łączyć kropki i dostarczać nam

tej podstawy, nad którą prawnik może dalej pracować. To, co jest zauważalne i jest coraz więcej też tego rodzaju dostawców takich systemów, jednym z nich jest i wydaje mi się, że nie zrobimy tutaj jakiegoś zbyt dużego produkt placementu, szczególnie, że ten produkt dotyczy dużych międzynarodowych korporacyjnych kancelarii, to jest produkt, który się nazywa Harvey Eye.

i ta nazwa Harvey jest nieprzypadkowo. Producent tego narzędzia dla dużych kancelarii wprost odniósł się do tego, że bazował na sukcesie firm na Netflixie o prawnikach. Wprowadził rozwiązanie, które też jest powielane w innych tego typu narzędziach, gdzie i na bazie źródeł zewnętrznych, i na bazie źródeł zewnętrznych.

Sztuczna inteligencja zaczyna komponować projekty pism, projekty umów, ale coś, co jest teraz wartością dodaną i z tego jak ja obserwuję ten rynek, to faktycznie jest to jakiegoś rodzaju nowum. Możemy trochę zaczynać programować pisma i umowy. W tym znaczeniu, że dopinamy do narzędzia sztucznej inteligencji określone źródła, tak jak powiedziałem, zewnętrzne albo wewnętrzne.

ale trochę tak jak w programowaniu obiektowym, dorzucamy do tego jeszcze nasze założenia, czyli co chcielibyśmy, żeby w piśmie zostało uwypuklone, wzięte pod uwagę jako grupy argumentacji i sztuczna inteligencja dopasowuje pierwszy projekt pisma pod to nasze prezdefiniowane de facto założenia, pod nasze prezdefiniowane wymogi, które są już też w poczekalni w formule blokowej.

W mojej ocenie jest to świetne rozwiązanie, które na pewno przyspieszy, zdynamizuje pracę prawników i unikając jakiegoś rodzaju negatywne czy może złośliwe zarzuty, że prawnicy wtedy już zupełnie będą działali na bazie kontrol C, kontrol V, to na pewno tak nie będzie, bo ci doświadczeni dojrzali prawnicy będą mogli dzięki temu dostarczyć tylko i wyłącznie jeszcze lepszą jakość dla klientów.

bo pominął mniej być może swoich własnych doświadczeń, pominął mniej aspektów, które sztuczna inteligencja jako trendy może wychwycić na rynku, że w danego typu postępowaniach zaczyna wygrywać argument X, co było szalenie istotne chociażby na poziomie kształtowania się orzecznictwa frankowego i tego, czy sądy unieważniają, czy unieważniają całe umowy frankowe, czy idą w jeszcze jakimś innym kierunku, bo tak jak wszyscy śledziliśmy...

ten obszar, oczywiście osoby zainteresowane, to to orzecznictwo, ono też kształtowało się latami. I tak na dobrą sprawę, ja bym podsumował to tak, że sztuczna inteligencja tutaj będzie trochę też minimalizowała, a wykluczała to ryzyko błędu człowieka. Błędu jako potencjału do tego, żeby pominąć jakąś istotną myśl, istotny argument albo...

brak spostrzeżenia, że dane argumenty mogą zyskiwać na czasie.

Wojtek (40:19)
Znaczy tak w krótkim w krótkim czasie bo tu podobnie właśnie prawnicy podobnie deweloperzy aczkolwiek nawet i wykładowcy akademicy tak nie boję się że te zawody zanikną bo nawet jeżeli tak jak mówisz używamy AI do wsparcia swojej pracy to koniec końców no i tu odnośnik do kilku pytań wcześniej.

bierzemy odpowiedzialność za to, co potem podpisujemy, To nie AI, a ty wysyłasz to pismo i wiesz, co potem z tym dalej fantem zrobić. takie pytanie pojawiające się, jak gdyby... No jest jeden odcinek, który wyjdzie, jeszcze nie wyszedł, jest nagrany i tam rozmawiam z kolegami, deweloperami właśnie o podobnych zagadnieniach i teraz jest pytanie, czy...

czy AI, czy wykorzystanie tych asystentów chociażby do wyszukiwania tych danych, do przygotowywania tych umów, do jakiegoś wnioskowania. Czy to tak naprawdę zwiększa efektowność, czy raczej momentami bardziej komplikuje pracę? No bo przecież potrzebna jest raczej jakaś konieczność dodatkowej weryfikacji. Pojawia się pytanie, na ile ty jako specjalista możesz temu modelowi zaufać?

Rafał (41:43)
No właśnie i tu dotykamy sedna, które też przewinęło się już w naszej dyskusji i to wydaje mi się będzie szalenie istotne i z perspektywy rynkowej i regulacyjnej, czyli jakość danych na których pracujemy, na których pracują narzędzia AI. I tutaj nie ma jakiejś jednej odpowiedzi na to pytanie. Oczywiście też miałem sam.

często w przypadkach takich czysto treningowych, jakieś dziwne odpowiedzi, czata GPT, który faktycznie dostarcza o przepisów, które nie istnieją. I tutaj rzeczywiście moja refleksja jest taka, że szalenie istotne jest, jakiego rodzaju zbiory danych podepniemy. Bo jeżeli zaufamy modelowi, który ma obsłużyć cały świat, w cudzysłowie, no to rzeczywiście musimy się spodziewać odpowiedzi bardzo przypadkowych wielokrotnie.

i ukształtowanych pod to, żeby każdy klient był zadowolony. Czyli mamy do czynienia z grzecznym czatem GPT, który przygotuje jakąkolwiek odpowiedź, trochę starając się wyczuwać nasz nastrój, być może ukierunkowanie pod odpowiedź naszego pytania i bardzo wiele różnych innych czynników. Natomiast tam, dlatego świadomie sygnalizowałem te zbiory danych, które musimy podczepiać pod te narzędzia, tam gdzie my zadbamy o to, żeby dostawca danych do tego...

działania był bardziej wiarygodny, żeby te dane były bardziej hermetyczne, upierunkowane pod daną branżę. Być może ten deployment narzędzia systemu sztucznej inteligencji nastąpi właśnie tylko i wyłącznie na naszych zbiorach. No to wtedy możemy mieć przekonanie i chyba nie tylko przekonanie, ale zobaczymy to po owocach. Przekonamy się po wynikach, że Czadu GPT będzie rzeczywiście z rozpędu narzędzie sztucznej inteligencji będzie

dostarczało nam lepszej jakości wyniki, bo rzeczywiście jeżeli zatrzymamy się na tym etapie, że trzeba będzie każdą linijkę zweryfikować, ja rozumiem, że koledzy, deweloperzy do tego, czy też w tym kierunku nawigowali, no to rzeczywiście może to tylko zwiększyć ilość pracy, a nie ją zmniejszyć. Ale znowu tutaj zadałbym trochę przewrotne pytanie, które...

I dotyczy prawników i każdej innej branży i też wielokrotnie programistów. My z różnego rodzaju wyszukiwarkami dotychczas mieliśmy to czynienie. Jeżeli uznalibyśmy, że narzędzia sztucznej inteligencji byłyby niepożądane, no to pytanie do jakiego etapu ewolucji tej cyfrowej musielibyśmy się cofnąć. Nie wiem, księgowi musieliby przestać księgować w programach komputerowych, a zacząć księgować z powrotem w zeszycie już.

może zbyt mocno wyostrzając ten przykład, ale jakby idę w tym kierunku, że rzeczywiście my musimy sami decydować, bo to my podnosimy odpowiedzialność, a tak długo jak człowiek będzie podejmował decyzję za firmę, to tak długo będzie chciał rozmawiać z konkretnym prawnikiem, z konkretnym deweloperem, z konkretnym dyrektorem finansowym, no to my rzeczywiście musimy odpowiedzieć sobie na pytanie, na czym my tak na dobrą sprawę chcemy

pracować, co nam ułatwia pracę, co jej nie ułatwia. No i rzeczywiście rynek, on już idzie w tym kierunku, że wymusza tą hermetyczność branżową, tak powiem. Jeżeli prawnik chce bazować na narzędziach sztucznej inteligencji, ogólnego przeznaczenia, czyli na tym przysłowiowym już czacie GPT, no to nie jest to na pewno dobry wybór.

Jest wielu dostawców branżowych bazujących tylko i wyłącznie na swoich zbiorach danych i warto jest pomyśleć o korzystaniu z takich narzędzi albo z takich baz dostarczanych przez te podmioty i wydaje mi się, że to jest odpowiedź na to pytanie. Jakość danych będzie szalenie istotna i rzeczywiście będziemy musieli mocno zwracać uwagę na to już nie tylko skąd jest model, jaki to jest model.

ale skąd są dane, którymi ten model się żywi.

Wojtek (45:58)
Ok, świetnie. bo wspomniałeś o czymś, co my nazywamy problemem juniorów, bo ty powiedziałaś, właśnie martwisz się trochę o młodszych kolegów i koleżanki, jak oni właśnie będą w stanie założyć kancelarię, no po prostu wejść w to. Czy też rzeczywiście, na przykład, widzisz taki, no bo my widzimy to w ten sposób, że w tej chwili, jeżeli mamy dobrego seniora...

to z wykorzystaniem asystentów AI ten senior jest naprawdę w stanie zrobić pracę dużo więcej, już nie chcę rzucać za ile tam osób, natomiast jest to senior, który ma doświadczenie, który ma intuicję, który wie jak ten produkt poskładać, jak ich narzędzi użyć i wie kiedy te narzędzia zaczynają, już tu mówię z takim znanym pojęciem, halucynować i...

i rzeczywiście pisać niestworzone rzeczy w tym kodzie. I my zadajemy sobie w branży pytanie, a co będzie za 5-10 lat, jeżeli właśnie w tej chwili firmy zatrudniają już mniej ludzi? No bo zwalniać to nie zwalniają najczęściej, ale szuka się coraz mniej juniorów, bo ci juniorzy już mogą być bardziej zastąpieni przez AI. No mówię, to zastąpienie polega na tym, że senior jest bardziej wydajny.

Też się tego rzeczywiście u was branża obawia, że za 5-10 lat nie będziemy mieli doświadczonych prawników.

Rafał (47:28)
Takiego rodzaju myśli się pojawiają, natomiast nie wiem, czy jest to jakiegoś rodzaju na ten moment diagnozowane jako obawa, z którą faktycznie branża prawnicza powinna się liczyć. Ja mam nadzieję, że tak i że to doprowadzi do tego, że bardziej starannie seniorzy będą zajmowali się prawniczymi juniorami.

funkcjonował długofalowo dobrze, tak na dobrą sprawę, to też w interesie tych seniorów jest to, żeby przychodzili do kancelerii następcy, którzy będą na początku uczeni, później będą coraz bardziej wspierać, a później wyręczać tego seniora po to, żeby stać samemu się seniorem. I tak jak powiedziałem, wydaje mi się, że to na szczęście chyba ten wątek sam się trochę doreguluje. Znowu te narzędzia wymuszą jakiegoś rodzaju nowe spojrzenie na kształcenie prawnika.

na przyuczanie młodszych kolegów i koleżanki w kancelariach do fachu. Chyba, że dojdziemy do decyzji, że wyręczamy też branżę prawniczą i chatboty będą podejmowały decyzje prawnicze w firmach. Wtedy to spojrzenie pani prezes, pana prezesa w oczy prawnikowi nie będzie potrzebne, ale to znowu, to już będziemy w zupełnie innej rzeczywistości. Będziemy się martwić licznie.

pewnie czymś zupełnie innym.

Wojtek (48:57)
No właśnie, ale ja o tego rodzaju przyszłość teraz chcę zapytać, ponieważ wcześniej już było wspomniana ta dyskryminacja, czyli tak jak mówię, jeżeli te dane, których często wspominasz będą takie, które dyskryminują nam pewne grupy, ale jeżeli użyjemy danych, które są czyste, które nie mają żadnych takich naleciałości związanych.

z jakąkolwiek dyskryminacją. To teraz czy prawnicy, sędziowie, adwokaci w pewnym momencie nie zostaną w większości, no bo pewnie nie w całości, ale zastąpieni przez zaawansowane modele wnioskujące, Czy prawnicy nie przyjmą bardziej takiej roli strażników etyki powiedzmy sobie, a większość interpretacji osądzania...

zajmie się ten rzeczony, zaawansowany model wnioskujący, ponieważ no jeżeli prawidłowo zostałby stworzony taki model, to on może być w stu procentach obiektywny, opierać się tylko na tym, co jest zapisane w prawie i tak naprawdę, poza tym, że ja rozumiem, że etyka tutaj waszego zawodu szeroko pojętego tak to...

to musi być bez jakichś nastrojów, preferencji, uprzedzeń, ale nie oszukujmy się, każdy jest tylko człowiekiem i ja w naprawdę myśleniu science fiction zastanawiam się czy taka absolutnie czysta interpretacja prawa przez model nie pasowałaby mi bardziej niż sędzia, który mógł mieć zły dzień.

Rafał (50:40)
To jest bardzo ciekawe spostrzeżenie i ja też pod nim bym się podpisał, że wielokrotnie gdybyśmy odcięli tą warstwę nastrojów osoby, która decyduje o czymkolwiek na jakimkolwiek odcinku, warstwę polityczną, być może warstwę dodatkowych własnych obaw, przemyśleń, to rzeczywiście można postawić zasadne pytanie, czy to nie byłoby lepsze i czy w tym kierunku pójdziemy, nie wiem.

Wydaje mi się, że na ten moment mogę ci odpowiedzieć na pierwszą część tego pytania, bo zacząłem od tej drugiej, argumentem z Terminatora. Tak jak zacząłeś zadawać to pytanie, to nie wiem, czy dobrze mi czas GPT podpowiedział, ale ta wojna z robotami, która doprowadziła do tego, z tym systemem Skynet, która doprowadziła do tego, że Terminator został...

wysłany do przeszłości, czyli do tego roku 1984 bodajże, to ona się toczyła w latach 2029 do 2032. Mniej więcej tak mi tutaj Chad GPT podpowiedział i chyba się mocno nie pomylił. Jest araks rok 2025 i jeszcze nie doszło do takiego wypuszczenia mocy decyzyjnych przez człowieka w kierunku maszyn i wydaje mi się, że to o czym mówisz dotyka znowu tego wątku.

bardzo istotnego, ja może trochę humorystycznie do tego się odniosłem. Natomiast wydaje mi się, że jest to szalenie istotne, bo w tym momencie, gdy człowiek podejdzie finalną, podejmie finalną nieodwracalną decyzję, że określone obszary przekazuje do decydowania sztucznej inteligencji, to wtedy no właśnie, albo będziemy musieli, będziemy mieli się czymś martwić, po jakimś czasie do tego dojdziemy, albo nie będziemy musieli się martwić, bo ta sztuczna inteligencja będzie wcześniej przygotowana i na tyle mocno...

zabezpieczona przez człowieka, jak fundacja przez fundatora w wielu przypadkach, że ten fundator się później nie musi niczym martwić w przyszłości. No ale wydaje mi się, że to jest pieśń przyszłości, że człowiek na ten moment samodzielnie przynajmniej nie zdecyduje, żeby oddać to w tak 100%. Aczkolwiek wydaje mi się, tego rodzaju projektu, w sposób kontrolowany, tam gdzie będzie...

można to weryfikować co najmniej retrospektywnie, to one coraz częściej będą się w różnego rodzaju kategoriach spraw bardziej trywialnych pojawiały, bo one najzwyczajniej w świecie przyspieszą podejmowanie decyzji, na przykład decyzji czy w przypadku jakichś zamieszek stosować areszt kilkudziesięciogodzinny czy też nie.

Teraz musi przyjechać w nocy sędzia, musi zdecydować, musi odbyć się jakiegoś rodzaju postępowania z udziałem człowieka. Co jest dla systemu uciążliwe i kosztowne? Być może w tego rodzaju sytuacjach, tylko znowu, będą oddziaływały na bezpośrednie prawej wolności Danego Kowalskiego, będzie to bardziej możliwe, jeżeli rzeczywiście będziemy mieli system, tak jak powiedziałeś, odseparowany od jakiegoś rodzaju złości, nerwów, aspektów politycznych.

i przekonamy się, że on działa, no właśnie, chciałoby się, że zero-jedynkowo, a tutaj nie mówimy o zero-jedynkowości w przypadku tego rodzaju systemów.

Wojtek (54:05)
Znaczy, no je się potem sprowadza do tego zera i jedynki, właśnie również jakimiś zasadami ustalonymi przez człowieka. Tutaj bardzo fajne porównanie rzeczywiście do Skynetu i tego, że tam została oddana decyzyjność. ja tylko przy takich dyskusjach zawsze też przypominam, że no wiadomo, znaczy o tyle ile film był rzeczywiście bardzo dobry pod kątem tego jak...

jak to wszystko może się zadziać, to tu trzeba powiedzieć, że to rzeczywiście nie takie science fiction po prostu, tylko mocno przemyślane. No to jednak różnica, którą trzeba tutaj zawsze wydaje mi się słuchaczom uwypuklić jest taka, że możemy stworzyć system podejmujący decyzje, ale wykonawstwo będzie dalej po stronie człowieka, tak? Czyli tak jak powiedziałeś, fajny przykład z tym...

sędziom w środku nocy czy kogoś zatrzymać na te 48 godzin czy nie. To tak, to i tak nie robot będzie zatrzymywał, a w dzisiejszych czasach powiedzmy sobie policjant, tak, i będziemy mieli skor tej decyzji, że na przykład decyzja została podjęta przez ten system na nie wiem, na 60 %...

to tak jak przy tej decyzji kredytowej, to już było lata temu tworzone, więc na spokojnie też mogę o tym mówić, był pewien poziom, tak, od którego ten mały kredyt, bo to też zależało od wielkości kredytu, był udzielany z automatu, ale był jakiś poziom, przy którym był odrzucany, bo nie było dalszego sensu, ale najwięcej, znaczy no nie najwięcej, tylko duża przestrzeń tego.

była jednak, gdzie szło to do weryfikacji człowieka, tak? Czyli tutaj znowu może nie chodzi o to, że totalnie byśmy się pozbyli tych sędziów podejmujących decyzje, ale może byłby jeden w Polsce na dyżurze, jakby system nie był pewny, to wtedy by odsyłał decyzję do niego.

Rafał (56:15)
Tak, a sam system miałby większą łatwość, żeby przetworzyć dane i w sposób zdalny przekazać temu sędziemu dyżurnemu te istotne elementy, które mogą ważyć na decyzję.

Wojtek (56:29)
Dokładnie bo tak jak na przykład standardowym też przykładem przytaczanym w dyskusjach o AI i zanikaniu zawodów są radiolodzy. O tym też rozmawiałem z kolegami developerami i tych radiologów już miało nie być. Oni dalej są oni dalej oceniają te wszystkie zdjęcia tomografie i tak dalej tylko robią to zupełnie inny sposób. Już dzisiaj nikt nie lata z tą kliszą do gabinetu.

tylko tak naprawdę liczba radiologów być może się zmniejszyła, ponieważ oni sobie siedzą gdzieś tam w jakimś jednym gabinecie i te zdjęcia przychodzą im online. Oceniają, wydają ten opis zdjęcia i to leci z powrotem do danej jednostki, w której to zdjęcie było wykonane.

Rafał (57:19)
Tak, to jest świetny przykład, bo rzeczywiście radiolodzy to jest taka branża, która już od lat się sygnalizuje, że jest zbyt mała liczba radiologów, a rzeczywiście wydaje mi się, to jest idealny przykład do tego, żeby zaimplementować systemy sztucznej inteligencji, bo tamta powtarzalność też jest skończona, tak na dobrą sprawę, i ilości przypadków, z którymi mamy do czynienia i rzeczywiście sztuczna inteligencja może to zrobić wielokrotnie.

znowu ujmując żadnej grupie zawodowej i nie odbierając fachu nikomu, to w wielu przypadkach wykluczamy zmęczenie chociażby, które tutaj jest dość istotnym faktorem i brak czasu.

Wojtek (58:02)
OK to już teraz tak zamykając powiedzmy sobie klamrą to wszystko o czym rozmawialiśmy gdybyś miał stworzyć jedną zasadę prawną która reguluje AI w prosty sposób tak żeby ułatwić nam wszystkim życie czy czy zapewnić nam bezpieczeństwo co byś co byś wprowadził.

Rafał (58:23)
Ciekawe, i trudne pytanie i duża odpowiedzialność.

Wojtek (58:31)
Mogę zadać ci jeszcze alternatywne, bo zawsze mam na końcu takie dwa smaczki. Drugie takie standardowe pytanie to jakiś jeden mit od strony prawnej o AI, który chciałbyś obawiać.

Rafał (58:35)
Dobranoc.

OK, jeżeli chodzi o ten mit, i dobrze, że mam okazję też z tobą rozmawiać, to od razu możesz też rozwijać moje wątpliwości, ale wydaje mi się, że dyskusja dotycząca naruszeń prawa autorskiego w przypadku AI jest trudna o tyle, że z jednej strony prawnicy

nie mogą inaczej odpowiedzieć na pytanie, czy jak skorzystam z sztucznej inteligencji, to naruszę cudze prawa autorskie, czy też nie. I prawnik, i ja też tak mówię, musi powiedzieć, że nie można wykluczyć ryzyka, że ktoś w utworze wytworzonym przez sztuczną inteligencję dopatrzy się jakiegoś utworu, dzieła wyjściowego, które było w areałach sztucznej, w bazach danych sztucznej inteligencji.

i dlatego jest to ryzyko użytkownika, czy korzystać z generatywnej sztucznej inteligencji, też nie. Ale z drugiej strony wydaje mi się, że to jest w dużej części mit nie dotyczący tego, jak odpowiadają prawnicy, tylko dotyczący tego, jak działa sztuczna inteligencja, bo wedle mojej wiedzy i rozmów z koleżeństwem deweloperskim wynika, że w praktyce jest to fizycznie niemożliwe, żeby do takiej sytuacji doszło.

Wojtek (1:00:07)
Czy żeby doszło do sytuacji tego plagiatu, udowodnienia plagiatu jak gdyby. Wiesz co.

Rafał (1:00:10)
Tak, tak, że jednak to rozdrobnienie i

sama mechanika działania jest na tyle szatkująca, atomizująca, że rzeczywiście pytanie, czy mielibyśmy do czynienia z narzędziem sztucznej inteligencji, gdyby ona wypuściła coś bardzo podobnego, no chyba, że w prompcie napiszemy, zrób mi bardzo podobny obraz do tego obrazu.

Wojtek (1:00:34)
No tak i teraz tutaj ja jako deweloper bo to jest tak to jest bardzo ciekawe zagadnienie i tu nie mam prostej na to odpowiedzi praktycznie nie mam żadnej odpowiedzi natomiast ja się zawsze staram posiłkować w rozmowie tym że zaraz przerzucę z powrotem odpowiedzialność naprawników ponieważ co definiuje nam.

plagiat, jak bardzo praca musi być na przykład podobna do tego, żebyśmy mówili już właśnie o naruszeniu praw autorskich. I mi się wydaje, jednak poza jakimiś tam marginalnymi przypadkami rzeczywiście, powiedzmy sobie, geniuszów artystycznych, czy to malarzy, muzyków, kompozytorów, rzeźbiarzy,

to tak naprawdę większość prac jest swego rodzaju pracami koniec końców odtwórczymi, bo na kimś się wzorujemy. Nawet ci, którzy wymyślili gdzieś tam bardziej swoje style, nurty w sztuce, oni też od czegoś wychodzili, to tutaj jest właśnie to, że tak ja się zgodzę, że ten plagiat będzie bardzo ciężki do...

do utworzenia, bo nawet jeżeli to jest tak jak mówisz technicznie gdzieś tam przetwarzane, szatkowane, tak koniec końców są to ciągi liczb, których coś tam powstaje. no to tak czy tak no mówię, tu trzeba byłoby się mocno zakłębić definicję tego naruszenia praw autorskich.

Rafał (1:02:19)
To dobrze, to poruszyliśmy i dziękuję za to pytanie, to też może dobrze skonstatowali, że to jest i mit i nie mit, bo rzeczywiście zgodzę się też z tym, że tak jak i my bazujemy na danych, które naszymi receptorami

do nas docierają, i maszyna czy narzędzie programistyczne też funkcjonuje czy też ona bazuje na danych, które do niego zostaną dostarczone. znaczy nie żyjemy w jakiejś bańce, tylko w jakiejś określonej rzeczywistości społeczno-kulturowej i określone prądy, określone uwarunkowania są wciskane we wszystkich, wszystkich dziełach.

Wojtek (1:03:08)
Teraz na przykład zdarza mi się oglądać na YouTube prezenter RMFFM Jacek Tomkowicz, taką serię, gdzieś to już słyszałem. wynajduje właśnie, znaczy nawet nie bardzo musi wynajdować, bo to jest prawnie uregulowane, że jeżeli na bazie jakiejś tam linii melodycznej nagram kolejną piosenkę, no to jakąś tam część tych tantiem.

płace po prostu temu oryginalnemu wykonawcy i on tam podaje przykłady naprawdę takich można było powiedzieć prawie osiedlowych zespołów gdzieś ze Stanów, gdzie ktoś znany coś usłyszał i nagle ci ludzie stają się bogaci, ponieważ jakaś gwiazda pop nagrała właśnie piosenkę gdzieś tam w tle używając kilku nutek i wiesz tu by trzeba było właśnie

Bo to też ja oglądam tylko jako taki zwyczajny konsument i nie wiem jak do końca się to ocenia, kiedy już trzeba komuś płacić za wykorzystanie jego koniec końców nut.

Rafał (1:04:15)
No dokładnie. To wydaje mi się, że to idealnie puentuje całą tą naszą dyskusję.

Wojtek (1:04:25)
Super, dziękuję ci bardzo za rozmowę.

Rafał (1:04:28)
Dzięki również, Wojciech.

Wojtek (1:04:31)
I mam nadzieję, że do usłyszenia.

Wojtek (1:04:44)
czegoś ciekawego. Teraz o tym, dlaczego 13-ka jest szczęśliwa. Co prawda, kiedy nagrywaliśmy ten odcinek nie wiedziałem jeszcze o tym, że będzie miał numer 13, natomiast

W trakcie nagrywania mieliśmy do tej pory największe problemy techniczne, jakimi spotkałem się przy nagrywaniu tego podcastu. To już 13 odcinków. Jednakże dzięki determinacji huporowi Rafała udało się ten odcinek nagrać do końca, za co mu dziękuję bardzo. Przypominam, że transkrypcję odcinka znajdziecie na hospoda.tech łamane na 13. Co za tydzień. A za tydzień będzie kolejna debata z Kamilem i Grzegorzem.

Tym razem podjęliśmy temat etyki V.I. Znaczy głównie to oni podjęli, bo to był jeden z odcinków tych dwóch odcinków, których ja generalnie nie miałem głosu, więc nie mogłem się za dużo udzielać. A jak mnie usłyszycie to zapewne bardzo skrzeczącego z ekranu. Przypominam również o newsletterze, na którym możecie się zapisać na stronie podcastu czyli hospoda.tech. Jeżeli jesteście ciekawi tego co będzie dalej.

zasubskrybujcie podcast w aplikacji, którym mnie słuchacie. Dajcie lajka, zostawcie komentarz, wystawcie ocenę. Będzie to dla mnie naprawdę duża motywacja do dalszego tworzenia tego podcastu, bo wiem, że podcast jest słuchany, natomiast jesteśmy jeszcze na początku, na dużym początku, bo nie ma się co mierzyć z podcastami, które są znacznie dłużej na rynku i mają...

dużo więcej słuchaczy, dużo większe, jak to się teraz mówi, zasięgi. Natomiast ja mam nadzieję, że te nasze zasięgi zbudujemy sobie tutaj z czasem. Ale feedback od was jest bardzo cenny. Jest naprawdę jedną z najcenniejszych rzeczy. Wiem, że to nie są wtedy tylko te liczby, statystyki, ale ktoś tego naprawdę słucha, może komuś się podoba, może coś trzeba byłoby poprawić. Naprawdę byłbym wdzięczny za feedback.

Przypominam również, że znajdziecie podcast na social mediach Facebook, X oraz Blue Sky. Dziękuję za dzisiaj i do usłyszenia.
